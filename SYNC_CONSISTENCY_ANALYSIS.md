# 同步机制数据一致性审查报告

**生成时间**: 2026-02-10
**审查范围**: SyncEngine 核心逻辑、冲突解决策略、加密机制、数据库事务处理

## 1. 概览

本次审查深入分析了 `SyncEngine` 及相关模块的实现，旨在识别可能导致数据丢失、不一致或同步失败的潜在风险。总体而言，该系统具备基本的并发控制、重试机制和事务保护，但在极端网络环境、时钟偏移、加密密钥变更及浏览器异常退出等 Edge Cases 下存在数据一致性隐患。

## 2. 详细风险分析

### 🔴 高风险 (High Risk)

#### 2.3 加密密钥变更缺乏迁移路径

- **位置**: `src/lib/crypto/encryption.ts`
- **问题描述**:
  `clearKey()` 仅删除本地存储的密钥，没有提供重新加密现有数据或迁移历史数据的机制。
- **风险场景**:
  用户如果因安全原因重置密钥，服务器上的所有历史数据将变得无法解密（永久丢失访问权），且本地未同步的数据也会因密钥不匹配而无法上传。
- **建议**:
  实现密钥轮换机制：保留旧密钥用于解密历史数据，使用新密钥加密新数据；或提供工具将所有历史数据下载、解密并用新密钥重新加密上传。

---

### 🟠 中风险 (Medium Risk)

#### 2.4 Push 操作的部分成功状态

- **位置**: `src/lib/sync/SyncEngine.ts`
- **问题描述**:
  推送操作是分批进行的，但在标记本地 `synced` 状态时存在间隙。
  ```typescript
  await this.withRetry(() => this.provider.push(batch, clientId));
  // ⚠️ 潜在间隙
  const updates = batch.map((op) => ({ ...op, synced: 1 }));
  await this.db.table('operations').bulkPut(updates);
  ```
- **风险场景**:
  如果 `provider.push` 成功（服务器收到数据），但在更新本地 `operations` 表之前脚本执行中断，下次同步时会重复推送相同数据。
- **建议**:
  虽然服务器端（如 Node Server）有 `INSERT OR IGNORE` 保护，但 CF Worker 实现直接追加数据会导致重复。建议在客户端或服务端增强幂等性检查。

#### 2.5 时钟偏移导致的数据覆盖

- **位置**: `src/lib/sync/SyncEngine.ts`
- **问题描述**:
  冲突解决依赖于比较本地记录的时间戳和远程操作的时间戳。
  ```typescript
  if (existingTimestamp && existingTimestamp > opTimestamp) {
    return; // 跳过应用
  }
  ```
- **风险场景**:
  如果本地设备时钟显著快于其他设备（例如快 10 分钟），本地的旧修改可能会错误地覆盖（或阻止）其他设备的新修改。
- **建议**:
  引入逻辑时钟（如 Lamport Clock 或 Vector Clock）作为辅助版本控制，或强制使用服务器时间作为唯一真理来源。

#### 2.6 解密失败阻塞同步队列

- **位置**: `src/lib/sync/crypto-helpers.ts`
- **问题描述**:
  单条记录解密失败会抛出异常，导致整个 Pull 批次失败。
- **风险场景**:
  如果某个恶意或损坏的数据包进入同步队列，客户端将陷入无限重试循环，无法同步后续的正常数据。
- **建议**:
  捕获单条解密错误，记录错误日志（"Poison Pill"），并跳过该记录，确保不阻塞整个队列。

---

### 🟡 低风险 (Low Risk)

#### 2.7 软删除状态可能被覆盖

- **位置**: `src/lib/sync/SyncEngine.ts`
- **问题描述**:
  删除操作被记录为带有 `deletedAt` 的更新。
- **风险场景**:
  如果在删除操作之后收到一个时间戳更早的 `update` 操作（由于网络延迟乱序到达），且冲突解决逻辑处理不当，可能会导致已删除的项目“复活”。

#### 2.8 游标更新与操作应用的非原子性

- **位置**: `src/lib/sync/SyncEngine.ts`
- **问题描述**:
  在无操作需要应用时，游标更新是单独进行的。虽然风险较低，但在极端情况下可能导致游标推进了但实际并未确认数据一致性。

## 3. Edge Cases 覆盖检查表

| Edge Case           | 当前状态   | 说明                                 |
| ------------------- | ---------- | ------------------------------------ |
| **网络完全中断**    | ✅ 已处理   | 包含重试机制和离线队列               |
| **并发 Push/Pull**  | ✅ 已处理   | 使用 `syncLock` 互斥                 |
| **操作回音 (Echo)** | ✅ 已处理   | 基于 `clientId` 过滤                 |
| **Schema 变更**     | ✅ 已处理   | `deferred_ops` 处理未知表操作        |
| **单条数据损坏**    | ❌ 未处理   | 会阻塞整个同步队列                   |
| **时钟严重偏移**    | ⚠️ 部分处理 | 依赖时间戳，存在覆盖风险             |
| **浏览器崩溃**      | ❌ 未处理   | `setTimeout` 导致操作记录可能丢失    |
| **密钥丢失**        | ❌ 未处理   | 数据无法恢复，无迁移路径             |
| **重复推送**        | ⚠️ 部分处理 | Node Server 有幂等保护，CF Worker 无 |

## 4. 改进建议 (Action Items)

### 🚀 立即修复 (Priority 1)

1. **移除 `setTimeout`**: 修改 `SyncEngine.ts` 中的 hook 逻辑，确保操作记录的可靠性。
2. **原子化冲突解决**: 将唯一索引冲突处理中的 `delete` + `put` 包裹在事务中。
3. **容错解密**: 修改 `pull` 逻辑，捕获单条解密失败，避免阻塞同步。

### 📅 规划改进 (Priority 2)

1. **增强幂等性**: 优化 CF Worker 端代码，防止重复数据追加。
2. **密钥管理**: 设计并实现密钥轮换和数据迁移流程。
3. **版本控制**: 引入逻辑时钟或版本向量，减少对物理时钟的依赖。

### 🔍 监控增强

1. 添加同步冲突率监控。
2. 添加解密失败计数监控。
3. 监控 `deferred_ops` 表的大小，防止累积过多未处理操作。
